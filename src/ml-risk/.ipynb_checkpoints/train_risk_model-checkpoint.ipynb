{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📒 train_risk_model.ipynb (Notebook Template - Beraborrow Risk Model w/ Blockscout)\n",
    "\n",
    "\n",
    "## 📌 Objective\n",
    "Train a risk classification model (0 = safe, 1 = risky) for Beraborrow vaults using on-chain activity data from Blockscout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl (198 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading numpy-2.2.6-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "Downloading scipy-1.15.3-cp311-cp311-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, threadpoolctl, six, numpy, joblib, idna, charset-normalizer, certifi, scipy, requests, python-dateutil, scikit-learn, pandas\n",
      "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 idna-3.10 joblib-1.5.1 numpy-2.2.6 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.3 scikit-learn-1.6.1 scipy-1.15.3 six-1.17.0 threadpoolctl-3.6.0 tzdata-2025.2 urllib3-2.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## 📦 Setup\n",
    "!pip install pandas requests scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 🔧 Configuration\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BLOCKSCOUT_API = \"https://rootstock.blockscout.com/api/v2\"\n",
    "ROOTSTOOCK_CONTRACT = \"0x2bEE6167f91d10Db23252e03dE039dA6B9047D49\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2025-05-31 20:25:39+00:00\n",
      "1    2025-05-31 19:02:47+00:00\n",
      "2    2025-05-31 16:06:13+00:00\n",
      "3    2025-05-31 16:00:39+00:00\n",
      "4    2025-05-31 15:46:35+00:00\n",
      "5    2025-05-31 15:40:01+00:00\n",
      "6    2025-05-31 12:25:54+00:00\n",
      "7    2025-05-31 12:24:28+00:00\n",
      "8    2025-05-31 12:22:55+00:00\n",
      "9    2025-05-31 11:12:00+00:00\n",
      "10   2025-05-31 11:09:22+00:00\n",
      "11   2025-05-31 10:15:22+00:00\n",
      "12   2025-05-31 10:11:16+00:00\n",
      "13   2025-05-31 09:29:34+00:00\n",
      "14   2025-05-31 09:07:46+00:00\n",
      "15   2025-05-31 09:04:36+00:00\n",
      "16   2025-05-31 08:48:35+00:00\n",
      "17   2025-05-31 07:03:41+00:00\n",
      "18   2025-05-31 07:00:00+00:00\n",
      "19   2025-05-31 06:48:40+00:00\n",
      "20   2025-05-31 06:46:19+00:00\n",
      "21   2025-05-31 02:39:48+00:00\n",
      "22   2025-05-31 02:34:39+00:00\n",
      "23   2025-05-31 02:20:46+00:00\n",
      "24   2025-05-31 02:09:58+00:00\n",
      "25   2025-05-30 23:44:17+00:00\n",
      "26   2025-05-30 23:41:41+00:00\n",
      "27   2025-05-30 23:39:03+00:00\n",
      "28   2025-05-30 23:36:45+00:00\n",
      "29   2025-05-30 21:11:05+00:00\n",
      "30   2025-05-30 18:17:00+00:00\n",
      "31   2025-05-30 18:13:26+00:00\n",
      "32   2025-05-30 17:22:32+00:00\n",
      "33   2025-05-30 17:22:32+00:00\n",
      "34   2025-05-30 17:11:39+00:00\n",
      "35   2025-05-30 17:06:53+00:00\n",
      "36   2025-05-30 17:04:33+00:00\n",
      "37   2025-05-30 15:56:46+00:00\n",
      "38   2025-05-30 14:52:10+00:00\n",
      "39   2025-05-30 12:49:21+00:00\n",
      "40   2025-05-30 12:48:33+00:00\n",
      "41   2025-05-30 12:44:59+00:00\n",
      "42   2025-05-30 12:03:43+00:00\n",
      "43   2025-05-30 11:58:22+00:00\n",
      "44   2025-05-30 09:35:33+00:00\n",
      "45   2025-05-30 08:58:54+00:00\n",
      "46   2025-05-30 06:20:36+00:00\n",
      "47   2025-05-30 06:07:23+00:00\n",
      "48   2025-05-30 03:31:17+00:00\n",
      "49   2025-05-30 01:20:05+00:00\n",
      "Name: timestamp, dtype: datetime64[ns, UTC] test timepstampt\n",
      "0     9.574016e-07\n",
      "1     9.574016e-07\n",
      "2     0.000000e+00\n",
      "3     5.000000e-04\n",
      "4     0.000000e+00\n",
      "5     0.000000e+00\n",
      "6     6.600000e-03\n",
      "7     0.000000e+00\n",
      "8     0.000000e+00\n",
      "9     1.400000e-03\n",
      "10    1.400000e-03\n",
      "11    0.000000e+00\n",
      "12    0.000000e+00\n",
      "13    4.861002e-04\n",
      "14    0.000000e+00\n",
      "15    0.000000e+00\n",
      "16    0.000000e+00\n",
      "17    0.000000e+00\n",
      "18    0.000000e+00\n",
      "19    0.000000e+00\n",
      "20    0.000000e+00\n",
      "21    1.116810e-03\n",
      "22    1.492931e-03\n",
      "23    2.000000e-03\n",
      "24    0.000000e+00\n",
      "25    0.000000e+00\n",
      "26    0.000000e+00\n",
      "27    0.000000e+00\n",
      "28    0.000000e+00\n",
      "29    0.000000e+00\n",
      "30    0.000000e+00\n",
      "31    0.000000e+00\n",
      "32    0.000000e+00\n",
      "33    0.000000e+00\n",
      "34    0.000000e+00\n",
      "35    0.000000e+00\n",
      "36    0.000000e+00\n",
      "37    0.000000e+00\n",
      "38    0.000000e+00\n",
      "39    0.000000e+00\n",
      "40    1.700000e-04\n",
      "41    0.000000e+00\n",
      "42    0.000000e+00\n",
      "43    0.000000e+00\n",
      "44    4.710000e-02\n",
      "45    3.100000e-03\n",
      "46    4.460000e-02\n",
      "47    0.000000e+00\n",
      "48    8.900000e-04\n",
      "49    1.900000e-04\n",
      "Name: value_eth, dtype: float64 Value Eth\n",
      "0          addLiquidityToV1\n",
      "1          addLiquidityToV1\n",
      "2             convertByPath\n",
      "3             convertByPath\n",
      "4             convertByPath\n",
      "5             convertByPath\n",
      "6          addLiquidityToV2\n",
      "7             convertByPath\n",
      "8     removeLiquidityFromV2\n",
      "9             convertByPath\n",
      "10            convertByPath\n",
      "11            convertByPath\n",
      "12         addLiquidityToV2\n",
      "13            convertByPath\n",
      "14            convertByPath\n",
      "15            convertByPath\n",
      "16            convertByPath\n",
      "17            convertByPath\n",
      "18            convertByPath\n",
      "19            convertByPath\n",
      "20            convertByPath\n",
      "21            convertByPath\n",
      "22            convertByPath\n",
      "23            convertByPath\n",
      "24    removeLiquidityFromV1\n",
      "25            convertByPath\n",
      "26            convertByPath\n",
      "27            convertByPath\n",
      "28            convertByPath\n",
      "29            convertByPath\n",
      "30    removeLiquidityFromV2\n",
      "31    removeLiquidityFromV1\n",
      "32            convertByPath\n",
      "33            convertByPath\n",
      "34            convertByPath\n",
      "35    removeLiquidityFromV2\n",
      "36    removeLiquidityFromV1\n",
      "37            convertByPath\n",
      "38            convertByPath\n",
      "39            convertByPath\n",
      "40            convertByPath\n",
      "41            convertByPath\n",
      "42            convertByPath\n",
      "43            convertByPath\n",
      "44            convertByPath\n",
      "45            convertByPath\n",
      "46            convertByPath\n",
      "47            convertByPath\n",
      "48            convertByPath\n",
      "49            convertByPath\n",
      "Name: method, dtype: object test the transaction method\n",
      "{'convertByPath': 40, 'removeLiquidityFromV2': 3, 'removeLiquidityFromV1': 3, 'addLiquidityToV1': 2, 'addLiquidityToV2': 2} method_counts tests\n",
      "✅ Feature set saved to ml-risk/rootstock_features.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/p_st54gd2lzf2ykdyw5ys6cc0000gn/T/ipykernel_30635/2290149179.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  transactions['timestamp'] = pd.to_datetime(transactions['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 📊 Fetch Transaction Data\n",
    "def fetch_txns(contract):\n",
    "    url = f\"{BLOCKSCOUT_API}/addresses/{contract}/transactions\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    return pd.DataFrame(r.json()[\"items\"])\n",
    "\n",
    "transactions = fetch_txns(ROOTSTOOCK_CONTRACT)\n",
    "transactions['timestamp'] = pd.to_datetime(transactions['timestamp'])\n",
    "transactions['value_eth'] = pd.to_numeric(transactions['value'], errors='coerce') / 1e18\n",
    "\n",
    "print(transactions['timestamp'], \"test timepstampt\")\n",
    "print(transactions['value_eth'], \"Value Eth\")\n",
    "\n",
    "\n",
    "transactions['method'] = transactions['method'].fillna(\"unknown\")\n",
    "method_counts = transactions['method'].value_counts().to_dict()\n",
    "\n",
    "print(transactions['method'], \"test the transaction method\")\n",
    "print(method_counts, \"method_counts tests\")\n",
    "\n",
    "transactions['from'] = transactions['from'].apply(lambda x: x['hash'] if isinstance(x, dict) else x)\n",
    "\n",
    "features = {\n",
    "    \"total_txns\": len(transactions),\n",
    "    \"unique_users\": transactions['from'].nunique(),\n",
    "    \"avg_value\": transactions['value_eth'].mean(),\n",
    "\n",
    "}\n",
    "\n",
    "features.update({\n",
    "    \"deposits\": method_counts.get(\"deposit\", 0),\n",
    "    \"withdraws\": method_counts.get(\"withdraw\", 0),\n",
    "    \"approvals\": method_counts.get(\"approve\", 0),\n",
    "    \"unique_methods\": transactions['method'].nunique(),\n",
    "    \"failed_txns\": len(transactions[transactions['status'] == 'failed']),\n",
    "})\n",
    "\n",
    "features[\"label\"] = 1 if features[\"avg_value\"] < 0.001 else 0\n",
    "\n",
    "\n",
    "pd.DataFrame([features]).to_csv(\"rootstock_features.csv\", index=False)\n",
    "\n",
    "print(\"✅ Feature set saved to ml-risk/rootstock_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.dropna(subset=[\"from\", \"timestamp\", \"value\"])\n",
    "token_transfers = token_transfers.dropna(subset=[\"from\", \"to\", \"value\"])\n",
    "internal_txns = internal_txns.fillna({'gas_used': 0})\n",
    "\n",
    "print(transactions, \"check transactions\")\n",
    "print(token_transfers, \"check token_transfers\")\n",
    "print(internal_txns, \"check internal_txns\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🧠 Feature Engineering\n",
    "\n",
    "\n",
    "\n",
    "features[\"txns_per_user\"] = features[\"total_txns\"] / features[\"unique_users\"] if features[\"unique_users\"] > 0 else 0\n",
    "features[\"net_token_flow\"] = features[\"token_inflow\"] - features[\"token_outflow\"]\n",
    "features[\"activity_score\"] = (\n",
    "    features[\"total_txns\"] + features[\"internal_txn_count\"] + features[\"token_inflow\"]\n",
    ") / (1 + features[\"last_activity_days\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🏷️ Labeling (Manual or Rule-Based for MVP)\n",
    "\n",
    "features[\"label\"] = 1 if features[\"last_activity_days\"] > 14 else 0  # Example logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🧪 Build Dataset\n",
    "\n",
    "df = pd.DataFrame([features])  # Append for multiple vaults if available\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
